---
layout: archive
author_profile: true
---

I am a Scientist at DeepMind in London. I want to understanding minds and brains to create AI. I did my PhD at MIT while 
working with Josh Tenenbaum in the Brain and Cognitive Sciences department. I am interested in integrating bottom-up 
computation (Deep Learning, Reinforcement Learning) with top-down computation (Program Synthesis, Probabilistic Programming, 
Simulators like Graphics and Game Engines) to create AI that learns and behaves like humans. 

<!-- <p>My work has led to the development of Deep Inverse Graphics (<a href="https://mrkulk.github.io/www_cvpr15/1999.pdf" style="color: rgb(0,255,0)">Picture</a>,<a href="https://arxiv.org/abs/1503.03167" style="color: rgb(0,255,0)">DCIGN</a>) , Probabilistic Programming and Inference (Picture, <a href="http://www.jmlr.org/papers/v18/15-615.html" style="color: rgb(0,255,0)">Variational Particle Approximations</a>, <a href="https://arxiv.org/abs/1307.0060" style="color: rgb(0,255,0)">Venture</a>), Deep Hierarchical Reinforcement Learning (<a href="https://arxiv.org/abs/1604.06057" style="color: rgb(0,255,0)">Hierarchical DQN</a>, <a href="https://arxiv.org/abs/1606.02396" style="color: rgb(0,255,0)">Deep Successor RL</a>) and Deep Reinforcement Learning for <a href="https://arxiv.org/abs/1506.08941" style="color: rgb(0,255,0)">language understanding</a>. -->
<!-- </p> -->

<p> My current research spans three questions:
  <ul>
    <li> <h3>What kind of programs can capture visual and motor complexity?</h3> Percetion in our brains runs in both conditional (wake) and 
      unconditional (sleep) modes. How do generative perceptual programs evolve and adapt during our life time? 
      What are the inductive biases or simplest set of initial program spaces? Can graphics and game engines provide a 
      general prior for visual perception? <a href="https://mrkulk.github.io/www_cvpr15/1999.pdf" style="color: rgb(0,255,0)">SPIRAL</a>
      is our latest attempt at using Deep Reinforcement Learning agents for inverse graphics. See my demo of SPIRAL running on a <a href="https://www.youtube.com/watch?v=v7V2udi5nCo" style="color: rgb(0,255,0)">robot</a>.  <a href="https://mrkulk.github.io/www_cvpr15/1999.pdf" style="color: rgb(0,255,0)">Picture</a> (<a href="http://www.pamitc.org/cvpr15/awards.php" style="color: rgb(100,100,100)">Best Paper Honorable Mention Award at CVPR 2015</a>)
      was my PhD work to learn probabilistic programs conditioned on images and accelerated/enabled by deep learning.
      <a href="https://mrkulk.github.io/www_cvpr15/1999.pdf" style="color: rgb(0,255,0)">DC-IGN</a> is a convolutional net and a learning algorithm to learn a neural rendering engine given
      raw videos. 
    </li>
    
    <li> <h3>What bottom-up sensory abstractions do we need for efficient, explorative and curious behavior?</h3>
      <a href="https://arxiv.org/abs/1604.06057" style="color: rgb(0,255,0)">Hierarchical DQN (hDQN)</a> is a hierarchical 
      deep RL agent that explores in the space of entities and geometric/logical relationships between them. <a href="https://arxiv.org/abs/1606.02396" style="color: rgb(0,255,0)">Deep Successor Representations</a>
      is an architecture to estimate goal-driven model-free representations for control. 
    </li>
    
    <li> <h3>Can games help agents to learn and ground language?</h3>
      I spent many hours in my childhood playing text based multi-user dungeons. This is how I primarily learnt about English.
      This motivated us to prototype Deep RL agents to learn to play text-based games and write a <a href="https://arxiv.org/abs/1506.08941" style="color: rgb(100,100,100)">paper</a> about it (<a href="http://www.emnlp2015.org/best-papers.html" style="color: rgb(0,255,0)">EMNLP 2015 Best Paper Honorable Mention Award</a>).
    </li>
  </ul>
</p>
<!-- <h3 id="unordered-lists-nested">Featured Articles</h3>
<ul>
  <li> Vision as Inverse Graphics: <a href="http://motherboard.vice.com/read/at-the-dawn-of-probalistic-programming">Motherboard Vice</a>, <a href="http://news.mit.edu/2015/better-probabilistic-programming-0413">MIT News</a>, ... </li>
  <li> Learning to perform physics experiments: <a href="https://www.newscientist.com/article/2112455-google-deepminds-ai-learns-to-play-with-physical-objects/">New Scientist</a>
  <li> Learning to play MUD/Text adventure games: <a href="http://phys.org/news/2015-09-language-games.html">Phys.org</a>, <a href="http://news.mit.edu/2015/learning-language-playing-computer-games-0924">MIT News</a> , ... </li>
</ul> -->

<h3 id="unordered-lists-nested">Highlights</h3>
<ul>
  <li> SPIRAL gets an oral at ICML 2018</li>
  <li> NIPS 2017 paper: Self-Supervised Intrinsic Image Decomposition [<a href="https://arxiv.org/abs/1711.03678" style="color: rgb(0,255,0)">PDF</a>]</li>
  <li> JMLR 2017 paper: Variational Particle Approximations [<a href="http://jmlr.org/papers/v18/15-615.html" style="color: rgb(0,255,0)">PDF</a>]</li>
  <li> CVPR 2017 paper: Synthesizing 3D Shapes via Modeling Multi-View Depth Maps and Silhouettes with Deep Generative Networks [<a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Soltani_Synthesizing_3D_Shapes_CVPR_2017_paper.pdf" style="color: rgb(0,255,0)">PDF</a>]</li>
  <li> Press Article about learning to perform physics experiments: <a href="https://www.newscientist.com/article/2112455-google-deepminds-ai-learns-to-play-with-physical-objects/" style="color: rgb(0,255,0)">New Scientist</a> </li>
  <li> June 2016: Successfully defended my PhD thesis at MIT </li>
  <li> Press Article about Inverse Graphics:  <a href="http://motherboard.vice.com/read/at-the-dawn-of-probalistic-programming" style="color: rgb(0,255,0)">Motherboard Vice</a>, <a href="http://news.mit.edu/2015/better-probabilistic-programming-0413" style="color: rgb(0,255,0)">MIT News</a>, ... </li> 
  <li> Press Article aboht learning to play MUD/Text adventure games: <a href="http://phys.org/news/2015-09-language-games.html">Phys.org</a>, <a href="http://news.mit.edu/2015/learning-language-playing-computer-games-0924" style="color: rgb(0,255,0)">MIT News</a> , ... </li>
  <li> 2012-2016: Singleton Fellow, Leventhal Fellow, MIT CBMM-Siemens Fellow </li>
</ul>

<h3 id="unordered-lists-nested">Talks and Workshops</h3>
<ul>
  <li> Invited tutorial talk @ ML Summer School in India [<a href="http://cvit.iiit.ac.in/mlsummerschool2017/speakers.html" style="color: rgb(0,255,0)">URL</a>]</li>
  <li> Invited to give tutorial talk @ DeepHack.RL winter school [<a href="https://www.youtube.com/watch?v=OCHwXxSW70o" style="color: rgb(0,255,0)">video</a>]</li>
  <li> Co-organizing <a href="https://uclmr.github.io/nampi/" style="color: rgb(0,255,0)">NAMPI</a> workshop at NIPS 2016 (Spain) </li>
  <li> Contributed talk @ <a href="https://sites.google.com/site/deeprlnips2016/" style="color: rgb(0,255,0)">Deep RL</a> workshop at NIPS 2016 [<a href="https://drive.google.com/file/d/0B1PUpk7kwWu-amdfcDRCbG9QU1lJZlZjdnBNQkhLSWxpa2ww/view" style="color: rgb(0,255,0)">Slides</a>]</li>
  <li> Dec 2015: Invited Talk @ <a href="https://www.meetup.com/bostonml/events/226326346/" style="color: rgb(0,255,0)">Bostom ML Meetup</a>
  <li> Co-organizing NIPS 2015 Workshop on <a href="http://www.blackboxworkshop.org/" style="color: rgb(0,255,0)"> Black box Learning and Inference</a> </li>
  <li> May 2015: Visiting DeepMind </li>
  <li> July 2015: Invited talk at Oxford </li>
</ul>

<!--
{% include base_path %}

<h3 class="archive__subtitle">{{ site.data.ui-text[site.locale].recent_posts | default: "Recent Posts" }}</h3>

{% for post in paginator.posts %}
  {% include archive-single.html %}
{% endfor %}

{% include paginator.html %}
--!>

